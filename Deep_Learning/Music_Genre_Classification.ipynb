{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import math\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING AUDIO BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'BR.wav'\n",
    "\n",
    "sig, sr = librosa.load(file, sr=22050)\n",
    "librosa.display.waveplot(sig, sr = sr)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = np.fft.fft(sig)\n",
    "mag = np.abs(fft)\n",
    "freq = np.linspace(0, sr, len(mag))\n",
    "hfreq = freq[:int(len(freq)/2)]\n",
    "hmag = mag[:int(len(mag)/2)]\n",
    "plt.plot(hfreq,hmag)\n",
    "plt.xlabel(\"Hz\")\n",
    "plt.ylabel(\"Mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_size = 512\n",
    "\n",
    "stft = librosa.core.stft(sig, hop_length = hop_size, n_fft = n_fft)\n",
    "spec = np.abs(stft)\n",
    "log_spec = librosa.amplitude_to_db(spec)\n",
    "librosa.display.specshow(log_spec,sr = sr, hop_length = hop_size)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Hz\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = librosa.feature.mfcc(sig, n_fft = 2048, hop_length = hop_size, n_mfcc = 13)\n",
    "librosa.display.specshow(MFCCs,sr = sr, hop_length = hop_size)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"MFCC\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING MUSIC GENRE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_P = \"genres\" # using the genre dataset from http://marsyas.info/downloads/datasets.html\n",
    "JSON_P = \"data.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30 # seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, n_segments=5):\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"mfcc\"   : [],\n",
    "        \"label\"  : []\n",
    "    }\n",
    "    \n",
    "    num_samples_per_segment = int (SAMPLES_PER_TRACK / n_segments)\n",
    "    expected_num_mfcc_vecs_per_segment = math.ceil(num_samples_per_segment / hop_length)\n",
    "    \n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        if dirpath is not dataset_path:\n",
    "            dirpath_components = dirpath.split(\"/\")\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\n Processing {}\".format(semantic_label))\n",
    "            \n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f) \n",
    "                sig, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                # process segment, extract mfcc, store data\n",
    "                \n",
    "                for s in range(n_segments):\n",
    "                    start_s = num_samples_per_segment * s\n",
    "                    end_s   = start_s + num_samples_per_segment\n",
    "                    mfcc = librosa.feature.mfcc(sig[start_s:end_s], sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "                    if len(mfcc) == expected_num_mfcc_vecs_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"label\"].append(i-1) # first iteration is the dataset path, so we ignore it\n",
    "                        print(\"{}, segment:{}\".format(file_path,s+1))\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mfcc(DATASET_P, JSON_P, n_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_p):\n",
    "    with open(dataset_p, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    inputs = np.array(data[\"mfcc\"])\n",
    "    targets = np.array(data[\"label\"])\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "inputs, targets = load_data(JSON_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_tr, in_test, t_tr, t_test = train_test_split(inputs, targets, test_size =0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD AND TRAIN THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 130, 13)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1690)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               865792    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,017,586\n",
      "Trainable params: 1,015,902\n",
      "Non-trainable params: 1,684\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((130,13))\n",
    "x = Flatten()(input_layer)\n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(10)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('softmax')(x)\n",
    "output_layer = Dropout(rate=0.3)(x)\n",
    "model1 = Model(input_layer, output_layer)\n",
    "opt = Adam(lr=0.0001)\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6997 samples, validate on 2999 samples\n",
      "Epoch 1/50\n",
      "6997/6997 [==============================] - 2s 294us/step - loss: 4.0431 - acc: 0.6826 - val_loss: 1.2301 - val_acc: 0.6219\n",
      "Epoch 2/50\n",
      "6997/6997 [==============================] - 2s 271us/step - loss: 4.1636 - acc: 0.6689 - val_loss: 1.3799 - val_acc: 0.5655\n",
      "Epoch 3/50\n",
      "6997/6997 [==============================] - 2s 271us/step - loss: 4.0663 - acc: 0.6746 - val_loss: 1.3337 - val_acc: 0.5905\n",
      "Epoch 4/50\n",
      "6997/6997 [==============================] - 2s 272us/step - loss: 4.0124 - acc: 0.6790 - val_loss: 1.2987 - val_acc: 0.5932\n",
      "Epoch 5/50\n",
      "6997/6997 [==============================] - 2s 270us/step - loss: 4.0915 - acc: 0.6694 - val_loss: 1.2608 - val_acc: 0.6085\n",
      "Epoch 6/50\n",
      "6997/6997 [==============================] - 2s 284us/step - loss: 4.0782 - acc: 0.6680 - val_loss: 1.3138 - val_acc: 0.5922\n",
      "Epoch 7/50\n",
      "6997/6997 [==============================] - 2s 280us/step - loss: 3.8673 - acc: 0.6882 - val_loss: 1.2506 - val_acc: 0.6132\n",
      "Epoch 8/50\n",
      "6997/6997 [==============================] - 2s 278us/step - loss: 4.0232 - acc: 0.6733 - val_loss: 1.3182 - val_acc: 0.5912\n",
      "Epoch 9/50\n",
      "6997/6997 [==============================] - 2s 293us/step - loss: 3.8824 - acc: 0.6809 - val_loss: 1.2600 - val_acc: 0.6125\n",
      "Epoch 10/50\n",
      "6997/6997 [==============================] - 2s 283us/step - loss: 3.9222 - acc: 0.6801 - val_loss: 1.2328 - val_acc: 0.6172\n",
      "Epoch 11/50\n",
      "6997/6997 [==============================] - 2s 286us/step - loss: 4.0962 - acc: 0.6687 - val_loss: 1.3056 - val_acc: 0.6095\n",
      "Epoch 12/50\n",
      "6997/6997 [==============================] - 2s 295us/step - loss: 3.8606 - acc: 0.6800 - val_loss: 1.2467 - val_acc: 0.6199\n",
      "Epoch 13/50\n",
      "6997/6997 [==============================] - 2s 296us/step - loss: 3.9504 - acc: 0.6743 - val_loss: 1.2683 - val_acc: 0.6072\n",
      "Epoch 14/50\n",
      "6997/6997 [==============================] - 2s 285us/step - loss: 3.9361 - acc: 0.6731 - val_loss: 1.3150 - val_acc: 0.6089\n",
      "Epoch 15/50\n",
      "6997/6997 [==============================] - 2s 280us/step - loss: 3.8494 - acc: 0.6829 - val_loss: 1.3339 - val_acc: 0.5975\n",
      "Epoch 16/50\n",
      "6997/6997 [==============================] - 2s 298us/step - loss: 3.9903 - acc: 0.6677 - val_loss: 1.3086 - val_acc: 0.6095\n",
      "Epoch 17/50\n",
      "6997/6997 [==============================] - 2s 284us/step - loss: 3.7539 - acc: 0.6814 - val_loss: 1.2995 - val_acc: 0.6099\n",
      "Epoch 18/50\n",
      "6997/6997 [==============================] - 2s 292us/step - loss: 3.8856 - acc: 0.6749 - val_loss: 1.3225 - val_acc: 0.6105\n",
      "Epoch 19/50\n",
      "6997/6997 [==============================] - 2s 290us/step - loss: 3.9265 - acc: 0.6703 - val_loss: 1.2947 - val_acc: 0.6139\n",
      "Epoch 20/50\n",
      "6997/6997 [==============================] - 2s 285us/step - loss: 3.8617 - acc: 0.6744 - val_loss: 1.2461 - val_acc: 0.6235\n",
      "Epoch 21/50\n",
      "6997/6997 [==============================] - 2s 289us/step - loss: 3.8497 - acc: 0.6736 - val_loss: 1.3111 - val_acc: 0.6059\n",
      "Epoch 22/50\n",
      "6997/6997 [==============================] - 2s 317us/step - loss: 3.7329 - acc: 0.6813 - val_loss: 1.3925 - val_acc: 0.5985\n",
      "Epoch 23/50\n",
      "6997/6997 [==============================] - 2s 308us/step - loss: 3.8387 - acc: 0.6726 - val_loss: 1.3073 - val_acc: 0.6185\n",
      "Epoch 24/50\n",
      "6997/6997 [==============================] - 2s 296us/step - loss: 3.7681 - acc: 0.6744 - val_loss: 1.3105 - val_acc: 0.6159\n",
      "Epoch 25/50\n",
      "6997/6997 [==============================] - 2s 289us/step - loss: 3.6787 - acc: 0.6836 - val_loss: 1.3288 - val_acc: 0.6109\n",
      "Epoch 26/50\n",
      "6997/6997 [==============================] - 2s 315us/step - loss: 3.6323 - acc: 0.6873 - val_loss: 1.2893 - val_acc: 0.6182\n",
      "Epoch 27/50\n",
      "6997/6997 [==============================] - 2s 304us/step - loss: 3.7386 - acc: 0.6763 - val_loss: 1.4214 - val_acc: 0.5845\n",
      "Epoch 28/50\n",
      "6997/6997 [==============================] - 2s 309us/step - loss: 3.7828 - acc: 0.6726 - val_loss: 1.3305 - val_acc: 0.6059\n",
      "Epoch 29/50\n",
      "6997/6997 [==============================] - 2s 299us/step - loss: 3.7073 - acc: 0.6769 - val_loss: 1.3711 - val_acc: 0.6025\n",
      "Epoch 30/50\n",
      "6997/6997 [==============================] - 2s 296us/step - loss: 3.6919 - acc: 0.6727 - val_loss: 1.3042 - val_acc: 0.6125\n",
      "Epoch 31/50\n",
      "6997/6997 [==============================] - 2s 291us/step - loss: 3.6815 - acc: 0.6759 - val_loss: 1.4460 - val_acc: 0.5965\n",
      "Epoch 32/50\n",
      "6997/6997 [==============================] - 2s 290us/step - loss: 3.6962 - acc: 0.6757 - val_loss: 1.3412 - val_acc: 0.6095\n",
      "Epoch 33/50\n",
      "6997/6997 [==============================] - 2s 293us/step - loss: 3.6381 - acc: 0.6773 - val_loss: 1.2994 - val_acc: 0.6239\n",
      "Epoch 34/50\n",
      "6997/6997 [==============================] - 2s 301us/step - loss: 3.5949 - acc: 0.6821 - val_loss: 1.4043 - val_acc: 0.5915\n",
      "Epoch 35/50\n",
      "6997/6997 [==============================] - 2s 292us/step - loss: 3.5606 - acc: 0.6820 - val_loss: 1.3374 - val_acc: 0.6125\n",
      "Epoch 36/50\n",
      "6997/6997 [==============================] - 2s 300us/step - loss: 3.4796 - acc: 0.6863 - val_loss: 1.4179 - val_acc: 0.5982\n",
      "Epoch 37/50\n",
      "6997/6997 [==============================] - 2s 302us/step - loss: 3.5897 - acc: 0.6786 - val_loss: 1.5096 - val_acc: 0.5869\n",
      "Epoch 38/50\n",
      "6997/6997 [==============================] - 2s 311us/step - loss: 3.5013 - acc: 0.6836 - val_loss: 1.9355 - val_acc: 0.5245\n",
      "Epoch 39/50\n",
      "6997/6997 [==============================] - 2s 293us/step - loss: 3.5342 - acc: 0.6780 - val_loss: 1.4229 - val_acc: 0.5939\n",
      "Epoch 40/50\n",
      "6997/6997 [==============================] - 2s 298us/step - loss: 3.5723 - acc: 0.6751 - val_loss: 1.3980 - val_acc: 0.5879\n",
      "Epoch 41/50\n",
      "6997/6997 [==============================] - 2s 296us/step - loss: 3.5084 - acc: 0.6800 - val_loss: 1.3644 - val_acc: 0.6179\n",
      "Epoch 42/50\n",
      "6997/6997 [==============================] - 2s 309us/step - loss: 3.4567 - acc: 0.6830 - val_loss: 1.3214 - val_acc: 0.6159\n",
      "Epoch 43/50\n",
      "6997/6997 [==============================] - 2s 299us/step - loss: 3.4913 - acc: 0.6767 - val_loss: 1.3379 - val_acc: 0.6199\n",
      "Epoch 44/50\n",
      "6997/6997 [==============================] - 2s 318us/step - loss: 3.5170 - acc: 0.6744 - val_loss: 1.4303 - val_acc: 0.6089\n",
      "Epoch 45/50\n",
      "6997/6997 [==============================] - 2s 301us/step - loss: 3.4067 - acc: 0.6853 - val_loss: 1.4267 - val_acc: 0.6005\n",
      "Epoch 46/50\n",
      "6997/6997 [==============================] - 2s 296us/step - loss: 3.3291 - acc: 0.6926 - val_loss: 1.4255 - val_acc: 0.6052\n",
      "Epoch 47/50\n",
      "6997/6997 [==============================] - 2s 296us/step - loss: 3.3988 - acc: 0.6842 - val_loss: 1.4773 - val_acc: 0.6019\n",
      "Epoch 48/50\n",
      "6997/6997 [==============================] - 2s 301us/step - loss: 3.5241 - acc: 0.6727 - val_loss: 1.4293 - val_acc: 0.6019\n",
      "Epoch 49/50\n",
      "6997/6997 [==============================] - 2s 298us/step - loss: 3.3846 - acc: 0.6834 - val_loss: 1.3724 - val_acc: 0.6145\n",
      "Epoch 50/50\n",
      "6997/6997 [==============================] - 2s 297us/step - loss: 3.4092 - acc: 0.6807 - val_loss: 1.4469 - val_acc: 0.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148149c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(in_tr, t_tr, validation_data=(in_test, t_test),epochs=50,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999/2999 [==============================] - 0s 52us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.446850855416479, 0.6028676225010973]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(in_test, t_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = np.array(['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'])\n",
    "\n",
    "preds = model1.predict(in_test)\n",
    "preds_single = GENRES[np.argmax(preds, axis = -1)]\n",
    "actual_single = GENRES[(t_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predicted: country\n",
      "\n",
      " correct: country\n",
      "\n",
      "predicted: reggae\n",
      "\n",
      " correct: disco\n",
      "\n",
      "predicted: reggae\n",
      "\n",
      " correct: reggae\n",
      "\n",
      "predicted: pop\n",
      "\n",
      " correct: country\n",
      "\n",
      "predicted: metal\n",
      "\n",
      " correct: country\n",
      "\n",
      "predicted: jazz\n",
      "\n",
      " correct: jazz\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.choice(range(len(in_test)), 6)\n",
    "for i, idx in enumerate(indices):\n",
    "    print(\"\\npredicted: {}\".format(preds_single[idx]))\n",
    "    print(\"\\n correct: {}\".format(actual_single[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
